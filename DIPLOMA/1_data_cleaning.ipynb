{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дипломный проект: Модель прогнозирования стоимости жилья для агентства недвижимости\n",
    "## ОЧИСТКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import json\n",
    "import re\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>private pool</th>\n",
       "      <th>propertyType</th>\n",
       "      <th>street</th>\n",
       "      <th>baths</th>\n",
       "      <th>homeFacts</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>city</th>\n",
       "      <th>schools</th>\n",
       "      <th>sqft</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>beds</th>\n",
       "      <th>state</th>\n",
       "      <th>stories</th>\n",
       "      <th>mls-id</th>\n",
       "      <th>PrivatePool</th>\n",
       "      <th>MlsId</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>240 Heather Ln</td>\n",
       "      <td>3.5</td>\n",
       "      <td>{'atAGlanceFacts': [{'factValue': '2019', 'fac...</td>\n",
       "      <td>Gas Logs</td>\n",
       "      <td>Southern Pines</td>\n",
       "      <td>[{'rating': ['4', '4', '7', 'NR', '4', '7', 'N...</td>\n",
       "      <td>2900</td>\n",
       "      <td>28387</td>\n",
       "      <td>4</td>\n",
       "      <td>NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611019</td>\n",
       "      <td>$418,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for sale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>single-family home</td>\n",
       "      <td>12911 E Heroy Ave</td>\n",
       "      <td>3 Baths</td>\n",
       "      <td>{'atAGlanceFacts': [{'factValue': '2019', 'fac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spokane Valley</td>\n",
       "      <td>[{'rating': ['4/10', 'None/10', '4/10'], 'data...</td>\n",
       "      <td>1,947 sqft</td>\n",
       "      <td>99216</td>\n",
       "      <td>3 Beds</td>\n",
       "      <td>WA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201916904</td>\n",
       "      <td>$310,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for sale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>single-family home</td>\n",
       "      <td>2005 Westridge Rd</td>\n",
       "      <td>2 Baths</td>\n",
       "      <td>{'atAGlanceFacts': [{'factValue': '1961', 'fac...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[{'rating': ['8/10', '4/10', '8/10'], 'data': ...</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>90049</td>\n",
       "      <td>3 Beds</td>\n",
       "      <td>CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>FR19221027</td>\n",
       "      <td>$2,895,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status private pool        propertyType             street    baths  \\\n",
       "0    Active          NaN  Single Family Home     240 Heather Ln      3.5   \n",
       "1  for sale          NaN  single-family home  12911 E Heroy Ave  3 Baths   \n",
       "2  for sale          NaN  single-family home  2005 Westridge Rd  2 Baths   \n",
       "\n",
       "                                           homeFacts fireplace  \\\n",
       "0  {'atAGlanceFacts': [{'factValue': '2019', 'fac...  Gas Logs   \n",
       "1  {'atAGlanceFacts': [{'factValue': '2019', 'fac...       NaN   \n",
       "2  {'atAGlanceFacts': [{'factValue': '1961', 'fac...       yes   \n",
       "\n",
       "             city                                            schools  \\\n",
       "0  Southern Pines  [{'rating': ['4', '4', '7', 'NR', '4', '7', 'N...   \n",
       "1  Spokane Valley  [{'rating': ['4/10', 'None/10', '4/10'], 'data...   \n",
       "2     Los Angeles  [{'rating': ['8/10', '4/10', '8/10'], 'data': ...   \n",
       "\n",
       "         sqft zipcode    beds state stories mls-id PrivatePool       MlsId  \\\n",
       "0        2900   28387       4    NC     NaN    NaN         NaN      611019   \n",
       "1  1,947 sqft   99216  3 Beds    WA     2.0    NaN         NaN   201916904   \n",
       "2  3,000 sqft   90049  3 Beds    CA     1.0    NaN         yes  FR19221027   \n",
       "\n",
       "       target  \n",
       "0    $418,000  \n",
       "1    $310,000  \n",
       "2  $2,895,000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data.csv', sep=',')\n",
    "data_backup = data.copy()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: 377185 18\n",
      "Типы данных: object    18\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>private pool</th>\n",
       "      <th>propertyType</th>\n",
       "      <th>street</th>\n",
       "      <th>baths</th>\n",
       "      <th>homeFacts</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>city</th>\n",
       "      <th>schools</th>\n",
       "      <th>sqft</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>beds</th>\n",
       "      <th>state</th>\n",
       "      <th>stories</th>\n",
       "      <th>mls-id</th>\n",
       "      <th>PrivatePool</th>\n",
       "      <th>MlsId</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>337267</td>\n",
       "      <td>4181</td>\n",
       "      <td>342452</td>\n",
       "      <td>377183</td>\n",
       "      <td>270847</td>\n",
       "      <td>377185</td>\n",
       "      <td>103115</td>\n",
       "      <td>377151</td>\n",
       "      <td>377185</td>\n",
       "      <td>336608</td>\n",
       "      <td>377185</td>\n",
       "      <td>285903</td>\n",
       "      <td>377185</td>\n",
       "      <td>226470</td>\n",
       "      <td>24942</td>\n",
       "      <td>40311</td>\n",
       "      <td>310305</td>\n",
       "      <td>374704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>337076</td>\n",
       "      <td>229</td>\n",
       "      <td>321009</td>\n",
       "      <td>1653</td>\n",
       "      <td>2026</td>\n",
       "      <td>297365</td>\n",
       "      <td>25405</td>\n",
       "      <td>4549</td>\n",
       "      <td>1184</td>\n",
       "      <td>39</td>\n",
       "      <td>348</td>\n",
       "      <td>24907</td>\n",
       "      <td>2</td>\n",
       "      <td>232944</td>\n",
       "      <td>43939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>for sale</td>\n",
       "      <td>Yes</td>\n",
       "      <td>single-family home</td>\n",
       "      <td>Address Not Disclosed</td>\n",
       "      <td>2 Baths</td>\n",
       "      <td>{'atAGlanceFacts': [{'factValue': '', 'factLab...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Houston</td>\n",
       "      <td>[{'rating': [], 'data': {'Distance': [], 'Grad...</td>\n",
       "      <td>0</td>\n",
       "      <td>32137</td>\n",
       "      <td>3 Beds</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No MLS#</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO MLS</td>\n",
       "      <td>$225,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>156104</td>\n",
       "      <td>4181</td>\n",
       "      <td>92206</td>\n",
       "      <td>672</td>\n",
       "      <td>52466</td>\n",
       "      <td>7174</td>\n",
       "      <td>50356</td>\n",
       "      <td>24442</td>\n",
       "      <td>4204</td>\n",
       "      <td>11854</td>\n",
       "      <td>2141</td>\n",
       "      <td>53459</td>\n",
       "      <td>115449</td>\n",
       "      <td>67454</td>\n",
       "      <td>3</td>\n",
       "      <td>28793</td>\n",
       "      <td>24</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          status private pool        propertyType                 street  \\\n",
       "count     337267         4181              342452                 377183   \n",
       "unique       159            1                1280                 337076   \n",
       "top     for sale          Yes  single-family home  Address Not Disclosed   \n",
       "freq      156104         4181               92206                    672   \n",
       "\n",
       "          baths                                          homeFacts fireplace  \\\n",
       "count    270847                                             377185    103115   \n",
       "unique      229                                             321009      1653   \n",
       "top     2 Baths  {'atAGlanceFacts': [{'factValue': '', 'factLab...       yes   \n",
       "freq      52466                                               7174     50356   \n",
       "\n",
       "           city                                            schools    sqft  \\\n",
       "count    377151                                             377185  336608   \n",
       "unique     2026                                             297365   25405   \n",
       "top     Houston  [{'rating': [], 'data': {'Distance': [], 'Grad...       0   \n",
       "freq      24442                                               4204   11854   \n",
       "\n",
       "       zipcode    beds   state stories   mls-id PrivatePool   MlsId    target  \n",
       "count   377185  285903  377185  226470    24942       40311  310305    374704  \n",
       "unique    4549    1184      39     348    24907           2  232944     43939  \n",
       "top      32137  3 Beds      FL     1.0  No MLS#         yes  NO MLS  $225,000  \n",
       "freq      2141   53459  115449   67454        3       28793      24      1462  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Размер датасета:', *data.shape)\n",
    "print('Типы данных:', data.dtypes.value_counts())\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее число пропущенных значений: 1869151\n",
      "\n",
      "Пропущ.значения по столбцам:\n",
      "\n",
      "private pool    98.89153\n",
      "mls-id          93.38733\n",
      "PrivatePool     89.31267\n",
      "fireplace       72.66196\n",
      "stories         39.95785\n",
      "baths           28.19253\n",
      "beds            24.20086\n",
      "MlsId           17.73135\n",
      "sqft            10.75785\n",
      "status          10.58314\n",
      "propertyType     9.20848\n",
      "target           0.65777\n",
      "city             0.00901\n",
      "street           0.00053\n",
      "zipcode          0.00000\n",
      "schools          0.00000\n",
      "state            0.00000\n",
      "homeFacts        0.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Общее число пропущенных значений:', data.isna().sum().sum(), end='\\n\\n')\n",
    "print('Пропущ.значения по столбцам:', (data.isna().sum()*100/len(data)).round(5).sort_values(ascending=False), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с данными data: очистка и предварительная работа\n",
    "### Для начала приведем данные в порядок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['PrivatePool'] vs DATA ['private pool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_print(*args, **kwargs):\n",
    "    '''Функция аналог print с определенными настройками end и sep.\n",
    "    '''\n",
    "    \n",
    "    default_settings = {'end': '\\n\\n', 'sep': '\\n'}\n",
    "    kwargs = {**default_settings, **kwargs}\n",
    "    print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'private pool':\n",
      "Yes    4181\n",
      "Name: private pool, dtype: int64\n",
      "\n",
      "'PrivatePool':\n",
      "yes    28793\n",
      "Yes    11518\n",
      "Name: PrivatePool, dtype: int64\n",
      "\n",
      "Объединение данных:\n",
      "0.0    332693\n",
      "1.0     44492\n",
      "Name: PrivatePool, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, какие значения встречаются в обоих полях\n",
    "p_print(\"'private pool':\", data['private pool'].value_counts())\n",
    "p_print(\"'PrivatePool':\", data['PrivatePool'].value_counts())\n",
    "\n",
    "# Допустим, что эти поля дополняют данные об объектах. Объединим их\n",
    "# сделаем перенос положительных значений из 'private pool'\n",
    "yes_pool_index = data[data['private pool']=='Yes'].index\n",
    "data['PrivatePool'][yes_pool_index] = 1\n",
    "\n",
    "# Пусть 1 будет означать, что бассейн точно есть\n",
    "data['PrivatePool'].replace(r'(yes|Yes)', 1, regex=True, inplace=True)\n",
    "data['PrivatePool'].replace(np.NaN, 0, inplace=True)\n",
    "p_print('Объединение данных:', data['PrivatePool'].value_counts())\n",
    "\n",
    "#  Удалим ненужный признак\n",
    "data.drop('private pool', axis=1, inplace=True)\n",
    "data['PrivatePool'] = data['PrivatePool'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['MLS-ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Питерские котики\\AppData\\Local\\Temp\\ipykernel_38248\\3942647606.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['MlsId'].iloc[mls_add_index] = data['mls-id'].iloc[mls_add_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пропусков в столбце 'MlsId':\n",
      "11.12\n",
      "\n",
      "Оценка малоинформативности:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_val_ratio</th>\n",
       "      <th>nunique_ratio</th>\n",
       "      <th>warning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MlsId</th>\n",
       "      <td>0.007</td>\n",
       "      <td>66.019</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      max_val_ratio nunique_ratio warning\n",
       "MlsId         0.007        66.019       -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Также два дублирующихся поля, причем одно из них имеет менее 18% пропусков, а другое более 90%.\n",
    "# Удалим второе, предварительно сохранив уникальную информацию в первое поле.\n",
    "\n",
    "mls_add_index = data[(data['MlsId'].isna()) & (~ data['mls-id'].isna())].index\n",
    "\n",
    "data['MlsId'].iloc[mls_add_index] = data['mls-id'].iloc[mls_add_index]\n",
    "data.drop(columns='mls-id', inplace=True)\n",
    "\n",
    "p_print('Кол-во пропусков в столбце \\'MlsId\\':', (data['MlsId'].isna().sum()*100/len(data)).round(2))\n",
    "\n",
    "# Но не является ли признак малоинформативным?\n",
    "# Создадим функцию для определения малоинформативности, чтобы использовать ее и в дальнейшем\n",
    "\n",
    "def check_informativeness(df_col=np.NaN, df=np.NaN):\n",
    "    \n",
    "    def calc_inform(col):\n",
    "        max_val_ratio = round(col.value_counts().max()*100/col.shape[0], 3)\n",
    "        nunique_ratio = round(col.nunique()*100/col.shape[0], 3)\n",
    "        warning = 'is over 95%' if (max_val_ratio>95) or (nunique_ratio>95) else '-'\n",
    "        \n",
    "        result = pd.DataFrame({\n",
    "            col.name: {\n",
    "                'max_val_ratio': max_val_ratio, \n",
    "                'nunique_ratio': nunique_ratio,\n",
    "                'warning': warning,\n",
    "            }\n",
    "        }).transpose()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    if df_col is not np.NaN:\n",
    "        return calc_inform(df_col)\n",
    "    \n",
    "    if df is not np.NaN:\n",
    "        df_dict = {}\n",
    "        \n",
    "        for col in df.columns:\n",
    "            df_dict[col] = calc_inform(df[col]).iloc[0].to_dict()\n",
    "    \n",
    "        result = pd.DataFrame(df_dict).transpose()\n",
    "        \n",
    "    return result\n",
    "    \n",
    "    \n",
    "p_print('Оценка малоинформативности:', end='\\n')\n",
    "display(check_informativeness(df_col=data['MlsId']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признак 'MlsId' имеет допустимые показатели \n",
    "# Тем не менее из его уникальных значений можно извлечь лишь информацию о штате или городе, которая уже есть в других признаках\n",
    "# Более того, данные по сути являются id из риелторской системы. Поэтому всё же удалим этот признак.\n",
    "data.drop('MlsId', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['fireplace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 строк fireplace:\n",
      "yes               50356\n",
      "Yes               20856\n",
      "1                 14544\n",
      "2                  2432\n",
      "Not Applicable     1993\n",
      "Fireplace           847\n",
      "3                   564\n",
      "Living Room         433\n",
      "LOCATION            399\n",
      "Wood Burning        311\n",
      "Name: fireplace, dtype: int64\n",
      "\n",
      "Топ-10 фраз fireplace:\n",
      "yes                71212\n",
      "1                  14546\n",
      "2                   2432\n",
      "not applicable      1993\n",
      "ceiling fan         1318\n",
      "gas logs            1272\n",
      "living room         1153\n",
      "wood burning        1108\n",
      "walk-in closets     1042\n",
      "fireplace            910\n",
      "Name: fireplace, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireplace = data_backup['fireplace'].copy().str.lower()\n",
    "p_print('Топ-10 строк fireplace:', data['fireplace'].value_counts()[:10])\n",
    "\n",
    "all_fireplace_phrases = fireplace.str.split(', ').explode()\n",
    "p_print('Топ-10 фраз fireplace:', all_fireplace_phrases.value_counts()[:10])\n",
    "\n",
    "# Сохраним основные фразы из признака о каминах в файл, чтобы удобнее было отбирать будущие категории\n",
    "with open('data/other/all_fireplace_phrases.csv', 'wb') as file:\n",
    "    all_fireplace_phrases.value_counts().to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговые категории fireplace:\n",
      "unknown        275466\n",
      "yes             74269\n",
      "1 frpl          18161\n",
      "no               3780\n",
      "2 frpl           2516\n",
      "gas              1072\n",
      "2 plus frpl       880\n",
      "wood              826\n",
      "decorative        215\n",
      "Name: fireplace, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Заменим пустые значения на unknown, что будет означать: тип камина неизвестен\n",
    "fireplace = fireplace.replace(np.NaN, 'unknown')\n",
    "\n",
    "# Подгружаем заранее подготовленный файл с основными типами каминов из признака\n",
    "fireplace_types = pd.read_csv('data/other/fireplace.csv')\n",
    "\n",
    "fireplace_dict = fireplace_types.set_index('fireplace_type').to_dict()['fireplace_mask']\n",
    "fireplace = fireplace.replace({fr'.*{key}.*': value for key, value in fireplace_dict.items()}, regex=True)\n",
    "\n",
    "fireplace_mask = fireplace_types['fireplace_mask'].unique()\n",
    "fireplace = fireplace.apply(lambda x: x if x in fireplace_mask else 'unknown')\n",
    "p_print('Итоговые категории fireplace:', fireplace.value_counts())\n",
    "\n",
    "data['fireplace_type'] = fireplace.astype('category')\n",
    "data.drop(columns='fireplace', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['stories'], DATA['baths'], DATA['beds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_helper(df_col, mode='full'):\n",
    "    '''Функция делит значения признака на числовые и оставшиеся, сохраняя их в файлы.\n",
    "    Таким образом это поможет найти \"лишние\" слова, от которых нужно очистить признаки до преобразования \n",
    "    '''\n",
    "    \n",
    "    df_col = df_col.str.lower().str.strip()\n",
    "    \n",
    "    df_col_num = df_col[df_col.str.contains(r'^[0-9,.]+$')==True]\n",
    "    df_col_alpha = df_col[~df_col.isin(df_col_num)]\n",
    "    \n",
    "    df_col_num = df_col_num.value_counts()\n",
    "    df_col_alpha = df_col_alpha.value_counts()\n",
    "    \n",
    "    dir_name = f'data/{df_col.name}'\n",
    "    if not os.path.exists(dir_name): os.mkdir(dir_name)\n",
    "    \n",
    "    with open(f'{dir_name}/alpha_{df_col_alpha.name}.csv', mode='w', newline='') as file:\n",
    "        df_col_alpha.reset_index().to_csv(file)\n",
    "        #print(df_col_alpha.reset_index())\n",
    "\n",
    "    # Выделим подстолбец с бессловесным описанием и сохраним его в отдельный файл\n",
    "    with open(f'{dir_name}/num_{df_col_num.name}.csv', mode='w', newline='') as file:\n",
    "        df_col_num.reset_index().to_csv(file)\n",
    "    \n",
    "    \n",
    "    if mode=='full':\n",
    "        p_print('alpha:', f'Длина столбца - {df_col_alpha.shape[0]}')\n",
    "        p_print('num:', f'Длина столбца - {df_col_num.shape[0]}')\n",
    "        p_print(f'Просмотрите файлы папки {dir_name} и преобразуйте столбец с помощью подходящих регулярных выражений, если необходимо.')\n",
    "    else: \n",
    "        p_print(f'alpha: {df_col_alpha.shape[0]}, num: {df_col_num.shape[0]}')\n",
    "    p_print('-------------------------------------------------------------------------')\n",
    "    \n",
    "    return df_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:\n",
      "Длина столбца - 176\n",
      "\n",
      "num:\n",
      "Длина столбца - 172\n",
      "\n",
      "Просмотрите файлы папки data/stories и преобразуйте столбец с помощью подходящих регулярных выражений, если необходимо.\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "alpha: 69, num: 172\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stories = data_backup['stories'].copy()\n",
    "stories = replacement_helper(stories)\n",
    "\n",
    "# Просмотрев результаты выполнения replacement_helper, сделаем замены\n",
    "stories_num_dict = {\n",
    "    r'one': r'1', \n",
    "    r'two': r'2', \n",
    "    r'bi-?': r'2',\n",
    "    r'three': r'3', \n",
    "    r'one and one half': r'1.5', \n",
    "    r'1 and 1 half': r'1.5',\n",
    "    r'.*fourplex.*': '4', \n",
    "    r'.*duplex.*': '2', \n",
    "    r'tri': r'3',\n",
    "    r'.*triplex.*': '3', \n",
    "    r'.*3plex.*': '3', \n",
    "    r'.*sixplex.*': '6', \n",
    "    r'.*quad.*': '4'\n",
    "}\n",
    "\n",
    "stories = stories.replace(stories_num_dict, regex=True)\n",
    "stories = stories.replace(r'^.*?([\\d+,.\\s]+)[\\s-]*(story|stories|level|levels).*$', r'\\1', regex=True)\n",
    "stories = stories.replace(r'.*(\\d+)\\s*(\\+|or more).*', r'\\1', regex=True)\n",
    "\n",
    "# Доп.проверка:\n",
    "stories = replacement_helper(stories, mode='short')\n",
    "\n",
    "def try_float(str):\n",
    "    try: \n",
    "        return float(str)\n",
    "    except: \n",
    "        return np.NaN    \n",
    "    \n",
    "# Окончательно конвертируем признак в числовой   \n",
    "stories = stories.apply(try_float)\n",
    "data['stories_num'] = stories.astype(np.float16)\n",
    "data.drop(columns='stories', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['BATHS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:\n",
      "Длина столбца - 142\n",
      "\n",
      "num:\n",
      "Длина столбца - 85\n",
      "\n",
      "Просмотрите файлы папки data/baths и преобразуйте столбец с помощью подходящих регулярных выражений, если необходимо.\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baths = data_backup['baths'].copy()\n",
    "baths = replacement_helper(baths)\n",
    "\n",
    "baths = baths.str.replace(r'[(ba|baths|bathrooms),.:\\s]', '', regex=True)\n",
    "baths = baths.str.replace('+', '', regex=False)\n",
    "\n",
    "baths = baths.apply(try_float)\n",
    "data['baths_num'] = baths.astype(np.float16)\n",
    "data.drop(columns='baths', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['beds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:\n",
      "Длина столбца - 1124\n",
      "\n",
      "num:\n",
      "Длина столбца - 60\n",
      "\n",
      "Просмотрите файлы папки data/beds и преобразуйте столбец с помощью подходящих регулярных выражений, если необходимо.\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Питерские котики\\AppData\\Local\\Temp\\ipykernel_38248\\4183736315.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  acreage_from_beds = beds[beds.str.contains(r'(acre|acres|sqft)')==True]\n"
     ]
    }
   ],
   "source": [
    "beds = data_backup['beds'].copy()\n",
    "beds = replacement_helper(beds)\n",
    "\n",
    "# Сохраним на всякий случай данные о площади и удалим их из столбца о спальнях\n",
    "acreage_from_beds = beds[beds.str.contains(r'(acre|acres|sqft)')==True]\n",
    "\n",
    "beds = beds.replace(r'\\b(bd|beds)\\b$', '', regex=True)\n",
    "beds = beds.replace(r'.*(\\d+)\\s(bedrooms).*', r'\\1', regex=True)\n",
    "beds = beds.replace(r'.*(acre|acres|sqft).*', np.NaN, regex=True)\n",
    "\n",
    "beds = beds.apply(try_float)\n",
    "data['beds_num'] = beds.astype(np.float16)\n",
    "data.drop(columns='beds', inplace=True)\n",
    "data['beds_num'] = data['beds_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['sqft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:\n",
      "Длина столбца - 13491\n",
      "\n",
      "num:\n",
      "Длина столбца - 11914\n",
      "\n",
      "Просмотрите файлы папки data/sqft и преобразуйте столбец с помощью подходящих регулярных выражений, если необходимо.\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqft = data_backup['sqft'].copy()\n",
    "sqft = replacement_helper(sqft)\n",
    "\n",
    "sqft = sqft.replace(r'.*([\\d|\\d+]?([,.]?\\d+))\\ssqft', r'\\1', regex=True)\n",
    "sqft = sqft.str.replace(r'(?<=\\d)[.,](?=\\d)', '.', regex=True)\n",
    "\n",
    "sqft = sqft.apply(try_float)\n",
    "data['sqft'] = sqft.astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['homeFacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year built</th>\n",
       "      <th>Remodeled year</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>Price/sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td>Central A/C, Heat Pump</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>$144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5828 sqft</td>\n",
       "      <td>$159/sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961</td>\n",
       "      <td>1967</td>\n",
       "      <td>Forced Air</td>\n",
       "      <td>Central</td>\n",
       "      <td>Attached Garage</td>\n",
       "      <td>8,626 sqft</td>\n",
       "      <td>$965/sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>Forced Air</td>\n",
       "      <td>Central</td>\n",
       "      <td>Detached Garage</td>\n",
       "      <td>8,220 sqft</td>\n",
       "      <td>$371/sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10,019 sqft</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377180</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>Other</td>\n",
       "      <td>Central</td>\n",
       "      <td>2 spaces</td>\n",
       "      <td>8,500 sqft</td>\n",
       "      <td>$311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377181</th>\n",
       "      <td>1924</td>\n",
       "      <td></td>\n",
       "      <td>Radiant</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>$337/sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377182</th>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1,600 sqft</td>\n",
       "      <td>$458/sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377183</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377184</th>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td>Electric</td>\n",
       "      <td>Central</td>\n",
       "      <td>No Data</td>\n",
       "      <td>6,969 sqft</td>\n",
       "      <td>$140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377185 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year built Remodeled year                 Heating  Cooling  \\\n",
       "0            2019                 Central A/C, Heat Pump            \n",
       "1            2019                                                   \n",
       "2            1961           1967              Forced Air  Central   \n",
       "3            2006           2006              Forced Air  Central   \n",
       "4                                                                   \n",
       "...           ...            ...                     ...      ...   \n",
       "377180       1990           1990                   Other  Central   \n",
       "377181       1924                                Radiant            \n",
       "377182       1950           1950                   Other            \n",
       "377183                                                              \n",
       "377184       2019                               Electric  Central   \n",
       "\n",
       "                Parking      lotsize Price/sqft  \n",
       "0                                          $144  \n",
       "1                          5828 sqft  $159/sqft  \n",
       "2       Attached Garage   8,626 sqft  $965/sqft  \n",
       "3       Detached Garage   8,220 sqft  $371/sqft  \n",
       "4                        10,019 sqft             \n",
       "...                 ...          ...        ...  \n",
       "377180         2 spaces   8,500 sqft       $311  \n",
       "377181             None               $337/sqft  \n",
       "377182                2   1,600 sqft  $458/sqft  \n",
       "377183                                           \n",
       "377184          No Data   6,969 sqft       $140  \n",
       "\n",
       "[377185 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "homefacts = data_backup['homeFacts'].copy()\n",
    "# Небольшое исправление: \n",
    "homefacts[160470] = homefacts[160470].replace('\"closet\"', \"'closet'\")\n",
    "\n",
    "def deserialize_homefacts(string):\n",
    "    '''Функция позволяет десериализовать данные. Возвращает 0, если в процессе возникла ошибка\n",
    "    '''\n",
    "    string = string.replace(\"'atAGlanceFacts'\", '\"atAGlanceFacts\"')\n",
    "    string = re.sub(r\":\\sNone,\", ': \"\",', string)\n",
    "    string = re.sub(r\"(?<=\\{)'|'(?=\\})\", '\"', string)\n",
    "    string = re.sub(r\"['|\\\"]([:|,]) ['|\\\"]\", r'\"\\1 \"', string)\n",
    "    \n",
    "    try:\n",
    "        res = json.loads(string)\n",
    "    except:\n",
    "        res = 0\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "homefacts_dict = homefacts.apply(deserialize_homefacts)\n",
    "homefacts_dict = homefacts_dict.apply(lambda x: x.get('atAGlanceFacts'))\n",
    "\n",
    "# Преобразуем полученные данные в датафрейм:\n",
    "hf_cols = [item['factLabel'] for item in homefacts_dict[0]]\n",
    "hf_data = homefacts_dict.apply(lambda x: [item.get('factValue') for item in x])\n",
    "\n",
    "# Формируем датафрейм, полученный из признака homeFacts\n",
    "homefacts_df = pd.DataFrame(columns=hf_cols, data=hf_data.to_list())\n",
    "display(homefacts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 377185 entries, 0 to 377184\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   Year built      377185 non-null  object\n",
      " 1   Remodeled year  377185 non-null  object\n",
      " 2   Heating         377185 non-null  object\n",
      " 3   Cooling         377185 non-null  object\n",
      " 4   Parking         377185 non-null  object\n",
      " 5   lotsize         377185 non-null  object\n",
      " 6   Price/sqft      377185 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 20.1+ MB\n"
     ]
    }
   ],
   "source": [
    "homefacts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year built</th>\n",
       "      <th>Remodeled year</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>Price/sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>377185</td>\n",
       "      <td>377185</td>\n",
       "      <td>377185</td>\n",
       "      <td>377185</td>\n",
       "      <td>377185</td>\n",
       "      <td>377185</td>\n",
       "      <td>377185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>230</td>\n",
       "      <td>154</td>\n",
       "      <td>1984</td>\n",
       "      <td>1445</td>\n",
       "      <td>3346</td>\n",
       "      <td>37393</td>\n",
       "      <td>6504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Central</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>62374</td>\n",
       "      <td>226110</td>\n",
       "      <td>109332</td>\n",
       "      <td>158754</td>\n",
       "      <td>175420</td>\n",
       "      <td>61455</td>\n",
       "      <td>63738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year built Remodeled year Heating  Cooling Parking lotsize Price/sqft\n",
       "count      377185         377185  377185   377185  377185  377185     377185\n",
       "unique        230            154    1984     1445    3346   37393       6504\n",
       "top                                       Central                           \n",
       "freq        62374         226110  109332   158754  175420   61455      63738"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homefacts_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поочередно разберем признаки homeFacts, чтобы дополонить данными датасет data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homeFacts: признаки 'Year built', 'Remodeled Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "homefacts_df['Year built'] = homefacts_df['Year built'].replace({'No Data': np.NaN, '': np.NaN}, regex=True).apply(float)\n",
    "homefacts_df['Remodeled year'] = homefacts_df['Remodeled year'].replace({'': np.NaN}, regex=True).apply(float)\n",
    "\n",
    "# Создание новых признаков:\n",
    "# DATA ['age'] - возраст объекта, \n",
    "# DATA ['is_remodeled'] - был ли объект обновлён.\n",
    "\n",
    "import datetime\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "data['age'] = current_year - homefacts_df['Year built']\n",
    "data['is_remodeled'] = homefacts_df['Remodeled year'].apply(lambda x: 1 if x is not np.NaN else 0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homeFacts: признак 'Heating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 фраз Heating:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "forced air          139497\n",
       "                    111541\n",
       "other                30148\n",
       "electric             16413\n",
       "central              12644\n",
       "heat pump            12379\n",
       "gas                  11531\n",
       "central air           9867\n",
       "central electric      8768\n",
       "no data               8611\n",
       "Name: Heating, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фрагмент файла для присвоения категорий:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heating_mask</th>\n",
       "      <th>heating_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>electric</td>\n",
       "      <td>electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heat pump</td>\n",
       "      <td>heat pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heat pump</td>\n",
       "      <td>pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas</td>\n",
       "      <td>propane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  heating_mask heating_type\n",
       "0          air          air\n",
       "1     electric     electric\n",
       "2    heat pump    heat pump\n",
       "3    heat pump         pump\n",
       "4          gas      propane"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Будем использовать все фразы из признака, чтобы выбрать наиболее популярные типы отопления\n",
    "heating = homefacts_df['Heating'].str.lower()\n",
    "print('Топ-10 фраз Heating:')\n",
    "display(heating.str.split(', ').explode().value_counts()[:10])\n",
    "\n",
    "# Основные тип ы отопления подгрузим из подготовленного файла\n",
    "heating_types = pd.read_csv('data/other/heating.csv', usecols=[0, 1])\n",
    "print('Фрагмент файла для присвоения категорий:')\n",
    "display(heating_types.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полученные категории heating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "other                      158948\n",
       "air                        153274\n",
       "electric                    28853\n",
       "gas                         13877\n",
       "heat pump                   10177\n",
       "baseboard                    8330\n",
       "radiant                      1745\n",
       "furnace/stove/fireplace      1242\n",
       "oil                           271\n",
       "zoned                         213\n",
       "water                         199\n",
       "steam                          56\n",
       "Name: Heating, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heating_dict = heating_types.set_index('heating_type').to_dict()['heating_mask']\n",
    "heating = heating.replace({fr'.*{key.strip()}.*': value for key, value in heating_dict.items()}, regex=True)\n",
    "\n",
    "heating_mask = list(heating_types['heating_mask'].unique())\n",
    "\n",
    "\n",
    "def to_categories(split, mask):\n",
    "    \n",
    "    for item in split: \n",
    "        if item in mask:\n",
    "            return item\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "heating = heating.str.split(', ').apply(lambda x: to_categories(x, heating_mask))\n",
    "\n",
    "print('Полученные категории heating')\n",
    "display(heating.value_counts())\n",
    "\n",
    "data['heating_type'] = heating.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homeFacts: признак 'Cooling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 фраз Cooling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "central                   162224\n",
       "                          124041\n",
       "central air                18296\n",
       "no data                    10616\n",
       "has cooling                 9730\n",
       "central electric            7976\n",
       "none                        7441\n",
       "wall                        4846\n",
       "central gas                 4600\n",
       "central a/c (electric)      3907\n",
       "Name: Cooling, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cooling = homefacts_df['Cooling'].str.lower().str.split(', ').explode()\n",
    "cooling.value_counts()[:10]\n",
    "\n",
    "print('Топ-10 фраз Cooling:')\n",
    "display(cooling.value_counts()[:10])\n",
    "\n",
    "# Много информации, отсылающей к системе отопления. Пока не будем использовать в датасете этот столбец."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homeFacts: признак 'Parking'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проработать пустые строки вида '' заменить их на np.NaN в data и homeFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 фраз Parking:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                   175430\n",
       "attached garage     80465\n",
       "2 spaces            28063\n",
       "detached garage     17019\n",
       "1 space             14253\n",
       "no data             13334\n",
       "carport             13175\n",
       "off street           8181\n",
       "3 spaces             4724\n",
       "on street            3370\n",
       "Name: Parking, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фрагмент файла для присвоения категорий:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parking_mask</th>\n",
       "      <th>parking_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no parking</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>garage</td>\n",
       "      <td>opener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garage</td>\n",
       "      <td>rv gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attached</td>\n",
       "      <td>attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detached</td>\n",
       "      <td>detached</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parking_mask parking_type\n",
       "0   no parking         none\n",
       "1       garage       opener\n",
       "2       garage      rv gate\n",
       "3     attached     attached\n",
       "4     detached     detached"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parking = homefacts_df['Parking'].str.lower()\n",
    "print('Топ-10 фраз Parking:')\n",
    "display(parking.str.split(', ').explode().value_counts()[:10])\n",
    "\n",
    "parking_types = pd.read_csv('data/other/parking.csv', sep=', ', engine='python')\n",
    "print('Фрагмент файла для присвоения категорий:')\n",
    "display(parking_types.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 фраз parking:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "other             194987\n",
       "attached           81968\n",
       "2 spaces           31170\n",
       "1 spaces           17340\n",
       "detached           14877\n",
       "carport             8745\n",
       "off street          6858\n",
       "3 spaces            5213\n",
       "4 spaces            3590\n",
       "garage              3388\n",
       "5 plus spaces       2707\n",
       "no parking          2415\n",
       "on street           1901\n",
       "driveway            1253\n",
       "slab                 509\n",
       "10 plus spaces       238\n",
       "oversized             26\n",
       "Name: Parking, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "reg_parking_dict = {\n",
    "    r'.*([1-4])(?!\\d).*(spaces|space).*': r'\\1 spaces',\n",
    "    r'.*(spaces|space).*([1-4])(?!\\d).*': r'\\1 spaces',\n",
    "    r'.*([5-9])(?!\\d).*(spaces|space).*': r'5 plus spaces', # означает от 5 до 9 м/м\n",
    "    r'.*(spaces|space).*([5-9])(?!\\d).*': r'5 plus spaces',\n",
    "    r'.*([1-9][0-9]+).*(spaces|space).*': r'10 plus spaces', \n",
    "    r'.*(spaces|space).*([1-9][0-9]+).*': r'10 plus spaces'\n",
    "}\n",
    "\n",
    "# Будем считать, что одинокая цифра в строке означает кол-во машиномест:\n",
    "parking = parking.replace(r'^(\\d+)$', r'\\1 spaces', regex=True)\n",
    "\n",
    "parking = parking.replace(reg_parking_dict, regex=True)\n",
    "\n",
    "main_parking_dict = parking_types.set_index('parking_type').to_dict()['parking_mask']\n",
    "parking = parking.replace({fr'.*{key.strip()}.*': fr'{value}' for key, value in main_parking_dict.items()}, regex=True)\n",
    "\n",
    "parking = parking.replace(r'garage', 'garage', regex=True)\n",
    "\n",
    "parking_mask = list(parking_types['parking_mask'].unique())\n",
    "parking = parking.str.split(', ').apply(lambda x: to_categories(x, parking_mask))\n",
    "\n",
    "print('Топ-10 фраз parking:')\n",
    "display(parking.value_counts())\n",
    "\n",
    "data['parking_type'] = parking.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homeFacts: признаки 'lotsize' и 'Price/sqft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  61455\n",
       "—                 25251\n",
       "no data            5330\n",
       "-- sqft lot        3819\n",
       "0.26 acres         3140\n",
       "                  ...  \n",
       "4,396 sqft            1\n",
       "8,661 sqft            1\n",
       "5,591 sqft            1\n",
       "5,716 sq. ft.         1\n",
       "7,084 sqft lot        1\n",
       "Name: lotsize, Length: 36608, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homefacts_df['lotsize'].str.lower().value_counts()\n",
    "# Мы ранее уже обработали признак с площадью объекта, текущий пока использовать не будем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               63738\n",
       "no data         1241\n",
       "$1/sqft          974\n",
       "no info          954\n",
       "$125/sqft        797\n",
       "               ...  \n",
       "$3,077/sqft        1\n",
       "$2,244/sqft        1\n",
       "$1,457             1\n",
       "$6,141             1\n",
       "$2,032             1\n",
       "Name: Price/sqft, Length: 6504, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homefacts_df['Price/sqft'].str.lower().value_counts()\n",
    "# В этом признаке есть непосредственная связь с таргетом, поэтому его тоже не будем использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='homeFacts', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['schools']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверим, сколько строк не удалось сериализовать:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "schools = data_backup['schools'].copy()\n",
    "\n",
    "\n",
    "def deserialize_schools(string):\n",
    "    '''Функция позволяет десериализовать данные. Возвращает 0, если в процессе возникла ошибка\n",
    "    '''\n",
    "    string = re.sub(r\"(?<=[,\\s|\\{|\\[])'|'(?=[:|,\\s|\\]])\", '\"', string)\n",
    "    string = re.sub(r'(?<=\\w\\s)\"|\"(?=\\s\\w)', \"'\", string)\n",
    "    string = string.replace(', None', ', \"\"')\n",
    "\n",
    "    try:\n",
    "        res = json.loads(string)[0]\n",
    "    except:\n",
    "        res = 0\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Формируем series из словарей, содержащих информацию о школах для всех объектов датасета\n",
    "schools_dict = schools.apply(deserialize_schools) \n",
    "print('Проверим, сколько строк не удалось сериализовать:')\n",
    "print(schools_dict[schools_dict==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_stat(schools_dict):\n",
    "    '''Функция для вычисления среднего рейтинга ближайших школ\n",
    "    '''\n",
    "    rating = schools_dict['rating']\n",
    "    rating = [re.sub(r'/.*', '', item) for item in rating]\n",
    "    rating = [int(item) for item in rating if item.isnumeric()]\n",
    "    \n",
    "    return round(statistics.mean(rating), 2) if len(rating)>0 else np.NaN\n",
    "\n",
    "\n",
    "def num_schools(schools_dict):\n",
    "    '''Функция для вычисления количества ближайших школ\n",
    "    '''\n",
    "    names = schools_dict['name']\n",
    "    return len(names) if names!=[] else np.NaN\n",
    "\n",
    "\n",
    "def distance_stat(schools_dict):\n",
    "    '''Функция для вычисления показателей расстояния до ближайших школ:\n",
    "        среднего, максимального, минимального\n",
    "    '''\n",
    "    distance = schools_dict['data']['Distance']\n",
    "    distance = [float(item.replace('mi', '')) for item in distance]\n",
    "    distance = [item for item in distance if item is not np.NaN]\n",
    "    \n",
    "    if len(distance) == 0: return np.NaN\n",
    "    \n",
    "    mean_distance = round(statistics.mean(distance), 2)\n",
    "    \n",
    "    return mean_distance\n",
    "\n",
    "\n",
    "mean_school_rating = schools_dict.apply(rating_stat)\n",
    "schools_number = schools_dict.apply(num_schools)\n",
    "mean_school_distance = schools_dict.apply(distance_stat)\n",
    "\n",
    "data['mean_school_rating'] = mean_school_rating\n",
    "data['schools_number'] = schools_number\n",
    "data['mean_school_distance'] = mean_school_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "grades = pd.Series([row['data']['Grades'] for row in schools_dict])\n",
    "grades = grades.apply(lambda lst: [re.split(r'[-|to|–|,]', elem) for elem in lst])\n",
    "grades = grades.apply(lambda lst: list(set(itertools.chain.from_iterable(lst))))\n",
    "grades = grades.apply(lambda lst: [elem.lower().strip() for elem in lst])\n",
    "\n",
    "grades_pk = grades.apply(lambda lst: 1 if ('pk' in lst) or ('presch' in lst) else 0)\n",
    "grades_k = grades.apply(lambda lst: 1 if 'k' in lst else 0)\n",
    "\n",
    "num_grades = grades.apply(lambda lst: list(filter(lambda x: x.isnumeric(), lst)))\n",
    "num_grades = num_grades.apply(lambda lst: [int(elem) for elem in lst])\n",
    "\n",
    "min_grade = num_grades.apply(lambda lst: min(lst) if len(lst)>0 else np.NaN)\n",
    "max_grade = num_grades.apply(lambda lst: max(lst) if len(lst)>0 else np.NaN)\n",
    "\n",
    "data['grades_pk'] = grades_pk\n",
    "data['grades_k'] = grades_k\n",
    "\n",
    "data['min_grade'] = min_grade\n",
    "data['max_grade'] = max_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('schools', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATE, CITY, STREET, ZIPCODE\n",
    "- Рассмотреть возможность загрузки достоверных списков штатов, городов, улиц.\n",
    "- Проанализировать повторяющиеся индексы - не ошибка ли это?\n",
    "- Кодировка или удаление?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список штатов из датасета:\n",
      "['NC' 'WA' 'CA' 'TX' 'FL' 'PA' 'TN' 'IA' 'NY' 'OR' 'DC' 'NV' 'AZ' 'GA'\n",
      " 'IL' 'NJ' 'MA' 'OH' 'IN' 'UT' 'MI' 'VT' 'MD' 'CO' 'VA' 'KY' 'MO' 'WI'\n",
      " 'ME' 'MS' 'OK' 'SC' 'MT' 'DE' 'Fl' 'BA' 'AL' 'OT' 'OS']\n",
      "\n",
      "Фрагмент проверочного файла Штаты/зипкоды:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Short Name</th>\n",
       "      <th>Capital City</th>\n",
       "      <th>ZIP Codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>35004;36925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>99501;99950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Short Name Capital City    ZIP Codes\n",
       "0  Alabama          AL   Montgomery  35004;36925\n",
       "1   Alaska          AK       Juneau  99501;99950"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Несуществующие штаты:\n",
      "['DC', 'Fl', 'BA', 'OT', 'OS']\n",
      "\n",
      "Количество пустых строк state:\n",
      "4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = data_backup['state'].copy()\n",
    "p_print('Список штатов из датасета:', (state.unique()))\n",
    "\n",
    "state_data = pd.read_csv('data/other/states_zipcodes.csv')\n",
    "#state_data['State'] = state_data['State'].str.strip()\n",
    "print('Фрагмент проверочного файла Штаты/зипкоды:')\n",
    "display(state_data.head(2))\n",
    "\n",
    "drop_states = []\n",
    "\n",
    "for item in state.unique():\n",
    "    if item not in list(state_data['Short Name']): drop_states.append(item)\n",
    "    \n",
    "p_print('Несуществующие штаты:', drop_states)\n",
    "#Округ Колумбию оставим, остальные преобразуем в np.NaN\n",
    "drop_states.remove('DC')\n",
    "state[state.isin(drop_states)] = np.NaN\n",
    "p_print('Количество пустых строк state:', state.isna().sum())\n",
    "\n",
    "data['state'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополним проверочную таблицу\n",
    "state_data.loc[state_data.shape[0]] = ['District of Columbia', 'DC', '', '20001;20599']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новое представление проверочной таблицы:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Short Name</th>\n",
       "      <th>Capital City</th>\n",
       "      <th>ZIP min</th>\n",
       "      <th>ZIP max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>35004</td>\n",
       "      <td>36925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Short Name Capital City ZIP min ZIP max\n",
       "0  Alabama          AL   Montgomery   35004   36925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zipcode = data['zipcode'].copy()\n",
    "\n",
    "# В строках встречаются зипкоды нестандартного вида. Исправим это \n",
    "data['zipcode'] = data['zipcode'].replace(r'-.*', '', regex=True)\n",
    "\n",
    "# Заменим колонку с зипом в проверочной табл. на две - с границами\n",
    "zips = state_data['ZIP Codes'].str.split(';')\n",
    "state_data['ZIP min'] = [zip_min for [zip_min, _] in zips]\n",
    "state_data['ZIP max'] = [zip_max for [_, zip_max] in zips]\n",
    "state_data.drop(columns='ZIP Codes', inplace=True)\n",
    "\n",
    "print('Новое представление проверочной таблицы:')\n",
    "display(state_data.head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь {штат: границы зипкода}:\n",
      "{'AL': ['35004', '36925'], 'AK': ['99501', '99950'], 'AZ': ['85001', '86556'], 'AR': ['71601', '72959'], 'CA': ['90001', '96162'], 'CO': ['80001', '81658'], 'CT': ['06001', '06928'], 'DE': ['19701', '19980'], 'FL': ['32003', '34997'], 'GA': ['30002', '39901'], 'HI': ['96701', '96898'], 'ID': ['83201', '83888'], 'IL': ['60001', '62999'], 'IN': ['46001', '47997'], 'IA': ['50001', '52809'], 'KS': ['66002', '67954'], 'KY': ['40003', '42788'], 'LA': ['70001', '71497'], 'ME': ['03901', '04992'], 'MD': ['20601', '21930'], 'MA': ['01001', '05544'], 'MI': ['48001', '49971'], 'MN': ['55001', '56763'], 'MS': ['38601', '39776'], 'MO': ['63001', '65899'], 'MT': ['59001', '59937'], 'NE': ['68001', '69367'], 'NV': ['88901', '89883'], 'NH': ['03031', '03897'], 'NJ': ['07001', '08989'], 'NM': ['87001', '88441'], 'NY': ['00501', '14925'], 'NC': ['27006', '28909'], 'ND': ['58001', '58856'], 'OH': ['43001', '45999'], 'OK': ['73001', '74966'], 'OR': ['97001', '97920'], 'PA': ['15001', '19640'], 'RI': ['02801', '02940'], 'SC': ['29001', '29945'], 'SD': ['57001', '57799'], 'TN': ['37010', '38589'], 'TX': ['73301', '88595'], 'UT': ['84001', '84791'], 'VT': ['05001', '05907'], 'VA': ['20101', '24658'], 'WA': ['98001', '99403'], 'WV': ['24701', '26886'], 'WI': ['53001', '54990'], 'WY': ['82001', '83128'], 'DC': ['20001', '20599']}\n",
      "\n",
      "Неопределенности при переносе границ зипкода:\n",
      "4\n",
      "\n",
      "Несоответствие штатов индексам в датасете:\n",
      "Кол-во: 33\n",
      "Примеры:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>ZIP_bounds</th>\n",
       "      <th>zip_state_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24403</th>\n",
       "      <td>WA</td>\n",
       "      <td>90109</td>\n",
       "      <td>[98001, 99403]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30261</th>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>[90001, 96162]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50596</th>\n",
       "      <td>FL</td>\n",
       "      <td>3316</td>\n",
       "      <td>[32003, 34997]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54590</th>\n",
       "      <td>TN</td>\n",
       "      <td>17238</td>\n",
       "      <td>[37010, 38589]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83522</th>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>[00501, 14925]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state zipcode      ZIP_bounds zip_state_check\n",
       "24403    WA   90109  [98001, 99403]           False\n",
       "30261    CA       0  [90001, 96162]           False\n",
       "50596    FL    3316  [32003, 34997]           False\n",
       "54590    TN   17238  [37010, 38589]           False\n",
       "83522    NY       0  [00501, 14925]           False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибки в соответствии индексов штатам:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>ZIP_bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33321</td>\n",
       "      <td>unknown state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33179</td>\n",
       "      <td>unknown state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193466</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11210</td>\n",
       "      <td>unknown state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231282</th>\n",
       "      <td>CA</td>\n",
       "      <td></td>\n",
       "      <td>[90001, 96162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235207</th>\n",
       "      <td>FL</td>\n",
       "      <td></td>\n",
       "      <td>[32003, 34997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>00000</td>\n",
       "      <td>unknown state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state zipcode      ZIP_bounds\n",
       "113694   NaN   33321   unknown state\n",
       "172273   NaN   33179   unknown state\n",
       "193466   NaN   11210   unknown state\n",
       "231282    CA          [90001, 96162]\n",
       "235207    FL          [32003, 34997]\n",
       "308229   NaN   00000   unknown state"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Составим словарь для проверки границ зипкодов по штату\n",
    "zip_dict = state_data[['Short Name', 'ZIP min', 'ZIP max']].set_index('Short Name').T.to_dict(orient='list')\n",
    "p_print('Словарь {штат: границы зипкода}:', zip_dict)\n",
    "\n",
    "# Перенесем границы зипкодов в основной датасет\n",
    "data['ZIP_bounds'] = data['state'].apply(lambda x: zip_dict.get(x, 'unknown state'))\n",
    "p_print('Неопределенности при переносе границ зипкода:', data['ZIP_bounds'][data['ZIP_bounds']=='unknown state'].shape[0])\n",
    "\n",
    "# Проверим соответствуют ли индексы из датасета необходимым границам:\n",
    "def zip_state_check_func(series):\n",
    "    \n",
    "    try:\n",
    "        return True if (int(series[0]) >= int(series[1][0])) & (int(series[0]) <= int(series[1][1])) else False\n",
    "    except:\n",
    "        return 'error'\n",
    "\n",
    "data['zip_state_check'] =  data[['zipcode', 'ZIP_bounds']].apply(zip_state_check_func, axis=1)\n",
    "print('Несоответствие штатов индексам в датасете:')\n",
    "print('Кол-во:', data['zip_state_check'].value_counts()[False])\n",
    "print('Примеры:')\n",
    "display(data[data['zip_state_check'] == False][['state', 'zipcode', 'ZIP_bounds', 'zip_state_check']].head())\n",
    "\n",
    "print('Ошибки в соответствии индексов штатам:')\n",
    "display(data[data['zip_state_check']=='error'][['state', 'zipcode', 'ZIP_bounds']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несоответствия будем устранять далее после обработки признаков города и адреса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных городов в датасете:\n",
      "1909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city = data_backup['city'].copy().str.lower()\n",
    "p_print('Число уникальных городов в датасете:', city.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def find_matching_strings(original_string, strings, similarity_threshold):\n",
    "    '''Функция для поиска похожих строк, которая поможет найти города, в написании которых содержится ошибка.\n",
    "    Возвращает список, где ключевому названию будут сопоставлены альтернативные вариантыб включая изначальный.\n",
    "    Поиск осуществляется согласно коэффициенту similarity_threshold.\n",
    "    '''\n",
    "    \n",
    "    matching_strings = []\n",
    "    for string in strings:\n",
    "        similarity_ratio = SequenceMatcher(None, original_string, string).ratio()\n",
    "        if similarity_ratio >= similarity_threshold:\n",
    "            matching_strings.append(string)\n",
    "    return matching_strings\n",
    "\n",
    "\n",
    "similarity_threshold = 0.9\n",
    "unique_cities = list(city.unique())\n",
    "unique_cities.remove(np.NaN)\n",
    "\n",
    "city_dict = {}\n",
    "\n",
    "for city_name in unique_cities:\n",
    "    unique_cities.remove(city_name)\n",
    "    matching_strings = find_matching_strings(city_name, unique_cities, similarity_threshold)\n",
    "    if len(set(matching_strings)) > 0: \n",
    "        city_dict[city_name] = list(set(matching_strings))\n",
    "        \n",
    "        \n",
    "cities_file = pd.Series(city_dict).explode()\n",
    "\n",
    "with open('data/other/city.csv', 'w', newline='') as file:\n",
    "    cities_file.to_csv(file)\n",
    "    \n",
    "# Далее вручную обработаем сохраненный файл, указывая в третьей колонке номер 1 или 2 в соответствии с предпочитаемым вариантом написания города\n",
    "# 0 - если оба варианта уникальны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_correct = pd.read_csv('data/other/city_correct.csv', names=['name_1', 'name_2', 'var'])\n",
    "cc = city_correct[city_correct['var'] > 0].apply(lambda x: [x['name_1'], x['name_2']] if x['var']==1 else {x['name_2'], x['name_1']}, axis=1)\n",
    "cc = list(cc)[1:]\n",
    "city_correct_dict = {key: value for [key, value] in cc}\n",
    "\n",
    "city = city.replace(city_correct_dict, regex=True)\n",
    "city.nunique()\n",
    "# Получилось очень мало замен :(\n",
    "\n",
    "data['city'] = city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['street]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Address Not Disclosed', 'Undisclosed Address', '(undisclosed Address)',\n",
       "       'Address Not Available', 'Unknown Address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street = data_backup['street'].copy()\n",
    "street.value_counts()[:5].index\n",
    "# Есть строки без указания адреса, позже они попадут в список неопределнных типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ключевые типы улиц по последнему слову в строке:\n",
      "['st', 'dr', 'ave', 'rd', 'ln', 'ct', 'apt', 'blvd', 'way', 'pl', 'unit', 'cir', 'ter', 'mls', 'ne', 's', 'nw', 'n', 'trl', 'se', 'sw', 'lot', 'e', 'w', 'a']\n",
      "\n",
      "Ключевые типы улиц по частоте слов в столбце:\n",
      "['st', 'dr', 'ave', 'rd', 'ln', 'n', 'w', 'ct', 's', 'sw', 'e', 'nw', 'apt', 'blvd', 'ne', 'plan', 'unit', 'pl', 'way', 'cir', 'in', 'se', 'ter', 'mls', 'park']\n",
      "\n",
      "Общий список из 25 предполагаемых типов улиц:\n",
      "['st', 'ter', 'apt', 'in', 'sw', 'trl', 'ln', 'ave', 'pl', 'dr', 'cir', 's', 'rd', 'ct', 'plan', 'se', 'ne', 'n', 'e', 'mls', 'w', 'unit', 'nw', 'lot', 'way', 'blvd', 'park', 'a']\n"
     ]
    }
   ],
   "source": [
    "def clean_streets(string):\n",
    "    '''Очистка строк с названиями улиц от знаков препинания и фрагментов с числами'''\n",
    "    \n",
    "    if string is np.NaN: return np.NaN\n",
    "    \n",
    "    string = re.sub(r'[,|.|#]', '', string.lower())\n",
    "    string = re.sub(r':', ' ', string)\n",
    "    string = re.sub(r'\\b\\w*\\d\\w*\\b|#\\d|\\d#', '', string)\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "def last_word_street_type(series):\n",
    "    '''Возвращает объект Series, в котором содержатся последние слова (окончания) из наименования улиц и их частота, \n",
    "    без учета знаков препинания и фрагментов с числами.\n",
    "    Исходим из предположения, что среди самых частых окончаний окажутся преимущественно типы улиц.'''\n",
    "    \n",
    "    temp_street = series.apply(clean_streets)\n",
    "    series_split = temp_street.str.split()\n",
    "    \n",
    "    return series_split.str.get(-1).value_counts()\n",
    "\n",
    "\n",
    "# Задаем ограничитель вывода предполагаемых типов улиц:\n",
    "n = 25\n",
    "\n",
    "print('Ключевые типы улиц по последнему слову в строке:')\n",
    "street_last_words = list(last_word_street_type(street).index[:n])\n",
    "print(street_last_words, end='\\n\\n')\n",
    "\n",
    "def most_frequent_words(series):\n",
    "    '''Возвращает объект Series, в котором содержится частота встречаемости каждого слова из названия улиц, \n",
    "    без учета знаков препинания и фрагментов с числами.\n",
    "    Исходим из предположения, что среди самых частых слов окажутся преимущественно типы улиц.\n",
    "    '''\n",
    "    common_list = []\n",
    "    temp_street = series.apply(clean_streets)\n",
    "    series_split = temp_street.str.split()\n",
    "    #series_split = series.str.replace(r'[,|.]', '', regex=True).str.replace(r'\\b\\w*\\d\\w*\\b|#\\d|\\d#', '', regex=True).str.split()\n",
    "\n",
    "    for split in series_split: \n",
    "        if split is np.NaN: continue\n",
    "        common_list.extend(split)\n",
    "    \n",
    "    return pd.Series(common_list).value_counts()\n",
    "\n",
    "\n",
    "print('Ключевые типы улиц по частоте слов в столбце:')\n",
    "street_most_freq = list(most_frequent_words(street).index[:n])\n",
    "print(street_most_freq, end='\\n\\n')\n",
    "\n",
    "# Объединим списки n предполагаемых типов, найденные двумя способами\n",
    "print(f'Общий список из {n} предполагаемых типов улиц:')\n",
    "main_street_types = list(set(street_last_words+street_most_freq))\n",
    "print(main_street_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Примеры употребления основных типов улиц.\n",
      "Найдите \"мусорные\" типы:\n",
      "\n",
      "1305 Holloway St , тип: st\n",
      "2845 Mcgill Ter NW, тип: ter\n",
      "14740 E Kentucky Dr APT 721, тип: apt\n",
      "The Landon Plan in American West Fox Hill Estates, тип: in\n",
      "8437 SW 137th Ave #8437 , тип: sw\n",
      "5578 Tiger Trl, тип: trl\n",
      "20919 Burnt Amber Ln , тип: ln\n",
      "4201 Ocean Ave, тип: ave\n",
      "5945 Atlas Pl SW, тип: pl\n",
      "707 Ginger Lake Dr Unit 136, тип: dr\n",
      "11749 Fitchwood Cir, тип: cir\n",
      "2154 S Balboa Plz, тип: s\n",
      "Chain Bridge Rd NW, тип: rd\n",
      "17708 NW Connett Meadow Ct, тип: ct\n",
      "Oasis Plan in K-Bar Ranch, тип: plan\n",
      "925 Potomac Ave SE, тип: se\n",
      "620 Peachtree St NE #701, тип: ne\n",
      "4810 N Ferdinand St, тип: n\n",
      "2405 E 19th Ave # 1-2, тип: e\n",
      "MLS #: CORC5938590, тип: mls\n",
      "3152 W Calavar Rd, тип: w\n",
      "9050 W Warm Springs Rd UNIT 2054, тип: unit\n",
      "12878 NW Milazzo Ln, тип: nw\n",
      "Lake Bend Ct Lot 24, тип: lot\n",
      "5406 Matanzas Way, тип: way\n",
      "7967 Hampton Park Blvd E, тип: blvd\n",
      "7768 Holly Park Ct NW, тип: park\n",
      "501 E 37th St #A, тип: a\n",
      "\n",
      "\n",
      "\n",
      "Очищенный основной список типов:\n",
      "['plan', 'trl', 'st', 'ave', 'ter', 'ln', 'pl', 'way', 'blvd', 'park', 'dr', 'cir', 'rd', 'ct']\n",
      "\n",
      "Дополнительный список типов улиц:\n",
      "['county', 'at', 'hwy', 'pass', 'highway', 'buildable', 'not', 'cv', 'address', 's', 'avenue', 'road', 'n', 'disclosed', 'loop', 'e', 'pkwy', 'mls', 'w', 'unit', 'undisclosed', 'lot', 'drive', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Рассмотрим примеры из столбца с подобранными типами улиц, чтобы избавиться от неподходящих.\n",
    "print('Примеры употребления основных типов улиц.', 'Найдите \"мусорные\" типы:', sep='\\n', end='\\n\\n')\n",
    "\n",
    "cleaned_street = street.apply(clean_streets)\n",
    "\n",
    "for elem in main_street_types:\n",
    "    street_subseries = street[cleaned_street.str.contains(fr\"\\b{elem}\\b\")==True]\n",
    "    print(f'{street_subseries.iloc[np.random.randint(len(street_subseries))]}, тип: {elem}')\n",
    "       \n",
    "print('\\n\\n')\n",
    "\n",
    "# Составим список 'мусорных' типов улиц для удаления из основного списка \n",
    "garbage_street_types = ['mls', 'apt', 's', 'w', 'n', 'e', 'ne', 'se', 'sw', 'nw', '#', '#1', '#2', 'a', 'b', 'unit', 'in', 'lot']\n",
    "main_street_types = list(set(main_street_types).difference(set(garbage_street_types)))\n",
    "print('Очищенный основной список типов:', main_street_types, end='\\n\\n', sep='\\n')\n",
    "\n",
    "\n",
    "def street_type_determine(string):\n",
    "    '''Проверяет, содержится ли метка основного типа улиц в строке. Возвращает метку класса или Nan, если метка не найдена.\n",
    "    '''\n",
    "    if string is np.NaN: return np.NaN\n",
    "    \n",
    "    # Будем использовать сплит строки и определять тип по первому совпадению из него с элементами основных типов.\n",
    "    str_split = re.split(r'[\\s|.|,]', string.lower())\n",
    "    str_split = list(filter(lambda x: x!='', str_split))\n",
    "    \n",
    "    for item in str_split[::-1]:\n",
    "        if item in main_street_types: return item\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "# Найдем названия улиц, которые не были отнесены к любому основному типу, и поищем основные типы среди них\n",
    "notype_street = street[street.apply(street_type_determine) == 'other']\n",
    "print('Дополнительный список типов улиц:', end='\\n')\n",
    "print(list(set(most_frequent_words(notype_street).index[:25]).difference(set(main_street_types))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доработаем список ключевых типов улиц\n",
    "main_street_types.extend(['path', 'pkwy', 'loop', 'hwy', 'cv', 'park', 'pass', 'rdg', 'pike', 'creek', 'clf'])\n",
    "# Унифицируем некоторые типы\n",
    "replace_dict = {'avenue': 'ave', 'road': 'rd', 'cove': 'cv', 'court': 'ct', 'place': 'pl', 'drive': 'dr', 'highway': 'hwy', 'lane': 'ln', 'cliff': 'clf', 'roadway': 'rdg'}\n",
    "street = street.replace(replace_dict, regex=True)\n",
    "\n",
    "# Сохраним полученные данные в новый столбец датасета\n",
    "data['street_type'] = data['street'].apply(street_type_determine)\n",
    "data.drop('street', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PropertyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число основный категорий propertyType:\n",
      "36\n",
      "\n",
      "Топ-10 категорий:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "single family        189693\n",
       "condo                 51461\n",
       "land                  31486\n",
       "townhome              18552\n",
       "multi family          12218\n",
       "traditional            7930\n",
       "other                  5830\n",
       "contemporary           3632\n",
       "manufactured home      3544\n",
       "co op                  3306\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "property_type = data_backup['propertyType'].copy()\n",
    "property_type = property_type.str.lower().str.replace('-',' ')\n",
    "\n",
    "# Подгрузим заранее подготовленные дубликаты propertyType\n",
    "pt_df = pd.read_csv('data/other/property_type.csv', sep=': ', names=['property_type', 'property_mask'], engine='python')\n",
    "pt_df.replace(r\"[',]\", '', regex=True, inplace=True)\n",
    "\n",
    "# Составим из них словарь для замены\n",
    "pt_replace_dict = pt_df.set_index('property_type').to_dict()['property_mask']\n",
    "property_type = property_type.replace(pt_replace_dict, regex=True)\n",
    "\n",
    "# Разобьем значения propertyType на список, чтобы можно было определить основной тип по первому вхождению\n",
    "property_type_split = property_type.apply(lambda x: re.split(r'[/|,]', x) if x is not np.NaN else np.NaN)\n",
    "\n",
    "main_property_types = ['apartment', 'condo', 'co op', 'single family', 'townhome', 'cape cod', 'colonial', 'contemporary', 'cottage', 'craftsman',\n",
    " 'greek revival', 'farmhouse', 'french country', 'mediterranean', 'midcentury', 'ranch', 'split level', 'tudor', 'victorian', 'european houses style',\n",
    " 'log home', 'manufactured home', 'cabin', 'land', 'multi family', 'traditional', 'transitional', 'bungalow', 'high rise', '1 story', '2 stories', 'penthouse', 'duplex', 'fourplex',\n",
    " 'garden home', 'other']\n",
    "\n",
    "\n",
    "def property_type_determine(str_split):\n",
    "    \n",
    "    if str_split is np.NaN: return np.NaN\n",
    "    \n",
    "    for elem in str_split:\n",
    "        elem = re.sub(r'\\(.*\\)', '', elem)\n",
    "        elem = elem.strip()\n",
    "        if elem in main_property_types: return elem\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "\n",
    "data['property_type'] = property_type_split.apply(property_type_determine)\n",
    "data.drop('propertyType', axis=1, inplace=True)\n",
    "p_print('Число основный категорий propertyType:', len(main_property_types))\n",
    "print('Топ-10 категорий:')\n",
    "display(data['property_type'].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ['status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статусы преобразованы согласно категориям\n",
      "Топ-10 категорий:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "activated                 304778\n",
       "foreclosed                  7228\n",
       "new construction            6165\n",
       "pending                     4917\n",
       "pre foreclosure             3679\n",
       "under contract showing      3386\n",
       "other                       2446\n",
       "active auction              1472\n",
       "contingency                  633\n",
       "price change                 563\n",
       "Name: status_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "status = data_backup['status'].copy()\n",
    "status = status.str.lower()\n",
    "\n",
    "# Подгрузим заранее подготовленный файл с категориями статуса\n",
    "status_df = pd.read_csv('data/other/status.csv')\n",
    "main_status = status_df['main status']\n",
    "\n",
    "def status_type_determine(string):\n",
    "    if string is np.NaN: return np.NaN\n",
    "    string = re.sub(r'\\s*/\\s*', ' ', string)\n",
    "    string = re.sub(r'(?<=coming soon).*', '', string)\n",
    "    string = re.sub(r'\\s+', ' ', string).strip().replace('-', ' ')\n",
    "    \n",
    "    if string in list(main_status): return status_df['mask'][list(main_status).index(string)]\n",
    "    \n",
    "    return 'other'\n",
    "        \n",
    "    \n",
    "data['status_type'] = status.apply(status_type_determine)\n",
    "data.drop('status', axis=1, inplace=True)\n",
    "print('Статусы преобразованы согласно категориям')\n",
    "print('Топ-10 категорий:')\n",
    "display(data['status_type'].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем итоговый датасет для дальнейшей работы\n",
    "\n",
    "data.drop(['ZIP_bounds', 'zip_state_check'], axis=1, inplace=True)\n",
    "data_2backup = data.copy()\n",
    "data_2backup.to_csv('data/data_2backup.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
